# Attention-Is-All-You-Need---note

There is a note for reading the paper([Attention Is All You Need])

[Attention Is All You Need]: https://arxiv.org/abs/1706.03762

#  An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale
There is a note for reading the paper ([An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale])

[An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale]:https://arxiv.org/abs/2010.11929


# Swin Transformer: Hierarchical Vision Transformer using Shifted Windows
There is a note for reaing the paper ([Swin Transformer: Hierarchical Vision Transformer using Shifted Windows])

[Swin Transformer: Hierarchical Vision Transformer using Shifted Windows]:https://arxiv.org/abs/2103.14030

